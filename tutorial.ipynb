{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Custom openai-gym environment tutorial\n",
    "\n",
    "This tutorial demonstrates how to create and load a custom environment for use with `gym`.\n",
    "\n",
    "## Elements of an environment\n",
    "\n",
    "An `environment` is an implementation of `gym.Env`.\n",
    "Any custom environment can be created by inheriting from the `gym.Env` class:\n",
    "```python\n",
    "class CustomEnv(gym.Env):\n",
    "    def step(self, action):\n",
    "        return\n",
    "\n",
    "    def reset(self):\n",
    "        return\n",
    "\n",
    "    @property\n",
    "    def action_space(self):\n",
    "        return\n",
    "\n",
    "    @property\n",
    "    def observation_space(self):\n",
    "        return\n",
    "\n",
    "    def reset(self):\n",
    "        return\n",
    "\n",
    "    def render(self):\n",
    "        return\n",
    "\n",
    "    def close(self):\n",
    "        return\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        return\n",
    "```\n",
    "\n",
    "Note that in this example, I have defined the following methods and attributes of `CustomEnv`:\n",
    "* step\n",
    "* action_space\n",
    "* obsevation_space\n",
    "* reset\n",
    "* *render*\n",
    "* *close*\n",
    "* *seed*\n",
    "\n",
    "The last three methods (render, close, and seed) are optional, and can be left blank."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training an env in openai-gym\n",
    "\n",
    "For our basic example, let us use the `CartPole-v1` ([source](https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py)) environment which comes with `gym`.\n",
    "We will train this using the `stable-baselines` library, but note that other approaches such as `rllib` can be used.\n",
    "\n",
    "In the `CartPole-v1` environment, the agent learns to balance a pole on top of a moving cart.\n",
    "The agent knows the full state of the system, that is the position and velocities of the cart and the pole given by \n",
    "$$\\mathrm{state} = \\left[x, \\dot{x}, \\theta, \\dot{\\theta}\\right].$$\n",
    "Since this is known to the agent, the observation space is defined as \n",
    "```python\n",
    "self.observation_space = spaces.Box(-high, high, dtype=np.float32)\n",
    "```\n",
    "where `high` is a length-4-array with bounding values for each of the state variables.\n",
    "\n",
    "This agent has an action space defined as \n",
    "```python\n",
    "self.action_space = spaces.Discrete(2)\n",
    "```\n",
    "which tells the model that there are two discrete actions, which represents moving left or right.\n",
    "\n",
    "Finally, the entire physics of the cart and pole are defined in `self.step()`.\n",
    "This is just an exercise in determining the applied force (due to the action) and calculating the updated positions and velocities using eulerian integration.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR) ## suppress warnings\n",
    "\n",
    "from stable_baselines.common.policies import MlpPolicy, MlpLstmPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines import PPO2\n",
    "from stable_baselines.common.evaluation import evaluate_policy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "# Optional: PPO2 requires a vectorized environment to run\n",
    "# the env is now wrapped automatically when passing it to the constructor\n",
    "# env = DummyVecEnv([lambda: env])\n",
    "\n",
    "policy_kwargs = dict(net_arch=[64, 64])\n",
    "# policy_kwargs = None\n",
    "model = PPO2(MlpPolicy, env, verbose=1, policy_kwargs=policy_kwargs) # MlpPolicy is 64x64 FC layers by default\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=100)\n",
    "\n",
    "model.learn(total_timesteps=5000)\n",
    "\n",
    "print(f\"Untrained mean_reward:\\t{mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=100)\n",
    "print(f\"Trained mean_reward:\\t{mean_reward:.2f} +/- {std_reward:.2f}\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wrapping the env in a DummyVecEnv.\n",
      "--------------------------------------\n",
      "| approxkl           | 8.6825254e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0192       |\n",
      "| fps                | 110           |\n",
      "| n_updates          | 1             |\n",
      "| policy_entropy     | 0.6930678     |\n",
      "| policy_loss        | -0.0015568695 |\n",
      "| serial_timesteps   | 128           |\n",
      "| time_elapsed       | 4.58e-05      |\n",
      "| total_timesteps    | 128           |\n",
      "| value_loss         | 40.957977     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.8545483e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0532        |\n",
      "| fps                | 295            |\n",
      "| n_updates          | 2              |\n",
      "| policy_entropy     | 0.69272757     |\n",
      "| policy_loss        | -0.00029773684 |\n",
      "| serial_timesteps   | 256            |\n",
      "| time_elapsed       | 1.24           |\n",
      "| total_timesteps    | 256            |\n",
      "| value_loss         | 45.051132      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.524344e-06  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0343        |\n",
      "| fps                | 528           |\n",
      "| n_updates          | 3             |\n",
      "| policy_entropy     | 0.6925578     |\n",
      "| policy_loss        | -3.310165e-05 |\n",
      "| serial_timesteps   | 384           |\n",
      "| time_elapsed       | 1.68          |\n",
      "| total_timesteps    | 384           |\n",
      "| value_loss         | 72.59697      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.0516549e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0491         |\n",
      "| fps                | 411            |\n",
      "| n_updates          | 4              |\n",
      "| policy_entropy     | 0.6923393      |\n",
      "| policy_loss        | -0.00029438036 |\n",
      "| serial_timesteps   | 512            |\n",
      "| time_elapsed       | 1.92           |\n",
      "| total_timesteps    | 512            |\n",
      "| value_loss         | 35.593273      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.7591681e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0277         |\n",
      "| fps                | 657            |\n",
      "| n_updates          | 5              |\n",
      "| policy_entropy     | 0.69213676     |\n",
      "| policy_loss        | -0.00055939215 |\n",
      "| serial_timesteps   | 640            |\n",
      "| time_elapsed       | 2.23           |\n",
      "| total_timesteps    | 640            |\n",
      "| value_loss         | 58.64271       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.0098385e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0236         |\n",
      "| fps                | 996            |\n",
      "| n_updates          | 6              |\n",
      "| policy_entropy     | 0.6907035      |\n",
      "| policy_loss        | -0.00034674536 |\n",
      "| serial_timesteps   | 768            |\n",
      "| time_elapsed       | 2.43           |\n",
      "| total_timesteps    | 768            |\n",
      "| value_loss         | 33.40161       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00010408853 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0604       |\n",
      "| fps                | 377           |\n",
      "| n_updates          | 7             |\n",
      "| policy_entropy     | 0.68885607    |\n",
      "| policy_loss        | -0.0022992291 |\n",
      "| serial_timesteps   | 896           |\n",
      "| time_elapsed       | 2.56          |\n",
      "| total_timesteps    | 896           |\n",
      "| value_loss         | 46.565823     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00015586994 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.118        |\n",
      "| fps                | 911           |\n",
      "| n_updates          | 8             |\n",
      "| policy_entropy     | 0.68760246    |\n",
      "| policy_loss        | -0.0015711592 |\n",
      "| serial_timesteps   | 1024          |\n",
      "| time_elapsed       | 2.91          |\n",
      "| total_timesteps    | 1024          |\n",
      "| value_loss         | 49.398026     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00014474693 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.103        |\n",
      "| fps                | 1031          |\n",
      "| n_updates          | 9             |\n",
      "| policy_entropy     | 0.68580365    |\n",
      "| policy_loss        | -0.0017472147 |\n",
      "| serial_timesteps   | 1152          |\n",
      "| time_elapsed       | 3.05          |\n",
      "| total_timesteps    | 1152          |\n",
      "| value_loss         | 63.259518     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00024721224 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0471        |\n",
      "| fps                | 1269          |\n",
      "| n_updates          | 10            |\n",
      "| policy_entropy     | 0.6841296     |\n",
      "| policy_loss        | -0.0013875286 |\n",
      "| serial_timesteps   | 1280          |\n",
      "| time_elapsed       | 3.17          |\n",
      "| total_timesteps    | 1280          |\n",
      "| value_loss         | 47.625557     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 3.4933022e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.143          |\n",
      "| fps                | 932            |\n",
      "| n_updates          | 11             |\n",
      "| policy_entropy     | 0.67959845     |\n",
      "| policy_loss        | -0.00041252444 |\n",
      "| serial_timesteps   | 1408           |\n",
      "| time_elapsed       | 3.27           |\n",
      "| total_timesteps    | 1408           |\n",
      "| value_loss         | 27.607916      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.7111055e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.128         |\n",
      "| fps                | 639           |\n",
      "| n_updates          | 12            |\n",
      "| policy_entropy     | 0.6735529     |\n",
      "| policy_loss        | -0.0007567392 |\n",
      "| serial_timesteps   | 1536          |\n",
      "| time_elapsed       | 3.41          |\n",
      "| total_timesteps    | 1536          |\n",
      "| value_loss         | 22.331293     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 5.6170305e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0989         |\n",
      "| fps                | 435            |\n",
      "| n_updates          | 13             |\n",
      "| policy_entropy     | 0.67805177     |\n",
      "| policy_loss        | -0.00025552465 |\n",
      "| serial_timesteps   | 1664           |\n",
      "| time_elapsed       | 3.61           |\n",
      "| total_timesteps    | 1664           |\n",
      "| value_loss         | 41.65126       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.3293024e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0637        |\n",
      "| fps                | 1240          |\n",
      "| n_updates          | 14            |\n",
      "| policy_entropy     | 0.67393106    |\n",
      "| policy_loss        | -0.0008027698 |\n",
      "| serial_timesteps   | 1792          |\n",
      "| time_elapsed       | 3.91          |\n",
      "| total_timesteps    | 1792          |\n",
      "| value_loss         | 42.850525     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.4688488e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.136         |\n",
      "| fps                | 788           |\n",
      "| n_updates          | 15            |\n",
      "| policy_entropy     | 0.6733807     |\n",
      "| policy_loss        | 0.00045455212 |\n",
      "| serial_timesteps   | 1920          |\n",
      "| time_elapsed       | 4.01          |\n",
      "| total_timesteps    | 1920          |\n",
      "| value_loss         | 34.907093     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.0001682438   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0395         |\n",
      "| fps                | 1268           |\n",
      "| n_updates          | 16             |\n",
      "| policy_entropy     | 0.6748999      |\n",
      "| policy_loss        | -0.00045382854 |\n",
      "| serial_timesteps   | 2048           |\n",
      "| time_elapsed       | 4.18           |\n",
      "| total_timesteps    | 2048           |\n",
      "| value_loss         | 55.11645       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.2981692e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.143         |\n",
      "| fps                | 1264          |\n",
      "| n_updates          | 17            |\n",
      "| policy_entropy     | 0.6771923     |\n",
      "| policy_loss        | -0.000776632  |\n",
      "| serial_timesteps   | 2176          |\n",
      "| time_elapsed       | 4.28          |\n",
      "| total_timesteps    | 2176          |\n",
      "| value_loss         | 40.489582     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0003846808  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0863        |\n",
      "| fps                | 781           |\n",
      "| n_updates          | 18            |\n",
      "| policy_entropy     | 0.68085325    |\n",
      "| policy_loss        | -8.943735e-05 |\n",
      "| serial_timesteps   | 2304          |\n",
      "| time_elapsed       | 4.38          |\n",
      "| total_timesteps    | 2304          |\n",
      "| value_loss         | 66.89402      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.174522e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0151        |\n",
      "| fps                | 982           |\n",
      "| n_updates          | 19            |\n",
      "| policy_entropy     | 0.67027414    |\n",
      "| policy_loss        | -0.0010993376 |\n",
      "| serial_timesteps   | 2432          |\n",
      "| time_elapsed       | 4.55          |\n",
      "| total_timesteps    | 2432          |\n",
      "| value_loss         | 42.421272     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.6015226e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0368        |\n",
      "| fps                | 1317          |\n",
      "| n_updates          | 20            |\n",
      "| policy_entropy     | 0.66951287    |\n",
      "| policy_loss        | 0.0004181614  |\n",
      "| serial_timesteps   | 2560          |\n",
      "| time_elapsed       | 4.68          |\n",
      "| total_timesteps    | 2560          |\n",
      "| value_loss         | 22.791609     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 7.3046103e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.06          |\n",
      "| fps                | 1251           |\n",
      "| n_updates          | 21             |\n",
      "| policy_entropy     | 0.67961055     |\n",
      "| policy_loss        | -0.00013092335 |\n",
      "| serial_timesteps   | 2688           |\n",
      "| time_elapsed       | 4.78           |\n",
      "| total_timesteps    | 2688           |\n",
      "| value_loss         | 51.34395       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.208277e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.00149       |\n",
      "| fps                | 1325          |\n",
      "| n_updates          | 22            |\n",
      "| policy_entropy     | 0.67650706    |\n",
      "| policy_loss        | -0.0007009207 |\n",
      "| serial_timesteps   | 2816          |\n",
      "| time_elapsed       | 4.88          |\n",
      "| total_timesteps    | 2816          |\n",
      "| value_loss         | 39.311527     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.0803646e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0428        |\n",
      "| fps                | 1272          |\n",
      "| n_updates          | 23            |\n",
      "| policy_entropy     | 0.6743018     |\n",
      "| policy_loss        | 0.00039312313 |\n",
      "| serial_timesteps   | 2944          |\n",
      "| time_elapsed       | 4.98          |\n",
      "| total_timesteps    | 2944          |\n",
      "| value_loss         | 72.38101      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 4.89567e-06    |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.00432       |\n",
      "| fps                | 1394           |\n",
      "| n_updates          | 24             |\n",
      "| policy_entropy     | 0.6731671      |\n",
      "| policy_loss        | -0.00025567145 |\n",
      "| serial_timesteps   | 3072           |\n",
      "| time_elapsed       | 5.08           |\n",
      "| total_timesteps    | 3072           |\n",
      "| value_loss         | 29.308867      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.0311578e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.115         |\n",
      "| fps                | 1371          |\n",
      "| n_updates          | 25            |\n",
      "| policy_entropy     | 0.6736803     |\n",
      "| policy_loss        | -5.303626e-05 |\n",
      "| serial_timesteps   | 3200          |\n",
      "| time_elapsed       | 5.17          |\n",
      "| total_timesteps    | 3200          |\n",
      "| value_loss         | 51.2314       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 3.0908107e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.024          |\n",
      "| fps                | 1324           |\n",
      "| n_updates          | 26             |\n",
      "| policy_entropy     | 0.66241306     |\n",
      "| policy_loss        | -0.00038965885 |\n",
      "| serial_timesteps   | 3328           |\n",
      "| time_elapsed       | 5.26           |\n",
      "| total_timesteps    | 3328           |\n",
      "| value_loss         | 33.887245      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 5.9472495e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.00741       |\n",
      "| fps                | 1414           |\n",
      "| n_updates          | 27             |\n",
      "| policy_entropy     | 0.67018336     |\n",
      "| policy_loss        | -0.00030595384 |\n",
      "| serial_timesteps   | 3456           |\n",
      "| time_elapsed       | 5.36           |\n",
      "| total_timesteps    | 3456           |\n",
      "| value_loss         | 41.4377        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.21258e-05   |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0349        |\n",
      "| fps                | 829           |\n",
      "| n_updates          | 28            |\n",
      "| policy_entropy     | 0.6662111     |\n",
      "| policy_loss        | -0.0005101899 |\n",
      "| serial_timesteps   | 3584          |\n",
      "| time_elapsed       | 5.45          |\n",
      "| total_timesteps    | 3584          |\n",
      "| value_loss         | 29.456385     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.2194925e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.103         |\n",
      "| fps                | 1289          |\n",
      "| n_updates          | 29            |\n",
      "| policy_entropy     | 0.66050243    |\n",
      "| policy_loss        | 3.5206438e-05 |\n",
      "| serial_timesteps   | 3712          |\n",
      "| time_elapsed       | 5.61          |\n",
      "| total_timesteps    | 3712          |\n",
      "| value_loss         | 31.39968      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 7.4173135e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0632         |\n",
      "| fps                | 1389           |\n",
      "| n_updates          | 30             |\n",
      "| policy_entropy     | 0.66895664     |\n",
      "| policy_loss        | -0.00040196895 |\n",
      "| serial_timesteps   | 3840           |\n",
      "| time_elapsed       | 5.71           |\n",
      "| total_timesteps    | 3840           |\n",
      "| value_loss         | 18.303795      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.000101879064 |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.135          |\n",
      "| fps                | 1317           |\n",
      "| n_updates          | 31             |\n",
      "| policy_entropy     | 0.67518        |\n",
      "| policy_loss        | -0.0015625486  |\n",
      "| serial_timesteps   | 3968           |\n",
      "| time_elapsed       | 5.8            |\n",
      "| total_timesteps    | 3968           |\n",
      "| value_loss         | 61.691936      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00017914803  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0358         |\n",
      "| fps                | 1341           |\n",
      "| n_updates          | 32             |\n",
      "| policy_entropy     | 0.6766574      |\n",
      "| policy_loss        | -0.00020447932 |\n",
      "| serial_timesteps   | 4096           |\n",
      "| time_elapsed       | 5.9            |\n",
      "| total_timesteps    | 4096           |\n",
      "| value_loss         | 32.779644      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 9.274713e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0351         |\n",
      "| fps                | 1283           |\n",
      "| n_updates          | 33             |\n",
      "| policy_entropy     | 0.6749542      |\n",
      "| policy_loss        | -0.00022588216 |\n",
      "| serial_timesteps   | 4224           |\n",
      "| time_elapsed       | 6              |\n",
      "| total_timesteps    | 4224           |\n",
      "| value_loss         | 42.20628       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 9.6145835e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0958       |\n",
      "| fps                | 1316          |\n",
      "| n_updates          | 34            |\n",
      "| policy_entropy     | 0.6679917     |\n",
      "| policy_loss        | 5.287642e-05  |\n",
      "| serial_timesteps   | 4352          |\n",
      "| time_elapsed       | 6.1           |\n",
      "| total_timesteps    | 4352          |\n",
      "| value_loss         | 14.603664     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.0332997e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.105         |\n",
      "| fps                | 1410          |\n",
      "| n_updates          | 35            |\n",
      "| policy_entropy     | 0.676471      |\n",
      "| policy_loss        | -0.0011773277 |\n",
      "| serial_timesteps   | 4480          |\n",
      "| time_elapsed       | 6.19          |\n",
      "| total_timesteps    | 4480          |\n",
      "| value_loss         | 38.2863       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.7367215e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0924       |\n",
      "| fps                | 1307          |\n",
      "| n_updates          | 36            |\n",
      "| policy_entropy     | 0.67574173    |\n",
      "| policy_loss        | 0.00088466285 |\n",
      "| serial_timesteps   | 4608          |\n",
      "| time_elapsed       | 6.29          |\n",
      "| total_timesteps    | 4608          |\n",
      "| value_loss         | 59.90962      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.5930629e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.0784         |\n",
      "| fps                | 1168           |\n",
      "| n_updates          | 37             |\n",
      "| policy_entropy     | 0.6634189      |\n",
      "| policy_loss        | -0.00040479028 |\n",
      "| serial_timesteps   | 4736           |\n",
      "| time_elapsed       | 6.38           |\n",
      "| total_timesteps    | 4736           |\n",
      "| value_loss         | 39.633144      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00022281976  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.123          |\n",
      "| fps                | 1213           |\n",
      "| n_updates          | 38             |\n",
      "| policy_entropy     | 0.671109       |\n",
      "| policy_loss        | -0.00023007614 |\n",
      "| serial_timesteps   | 4864           |\n",
      "| time_elapsed       | 6.49           |\n",
      "| total_timesteps    | 4864           |\n",
      "| value_loss         | 52.49348       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.483708e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.0294        |\n",
      "| fps                | 1141          |\n",
      "| n_updates          | 39            |\n",
      "| policy_entropy     | 0.6780411     |\n",
      "| policy_loss        | 0.00037842256 |\n",
      "| serial_timesteps   | 4992          |\n",
      "| time_elapsed       | 6.6           |\n",
      "| total_timesteps    | 4992          |\n",
      "| value_loss         | 30.51398      |\n",
      "--------------------------------------\n",
      "Untrained mean_reward:\t9.05 +/- 0.62\n",
      "Trained mean_reward:\t79.38 +/- 33.34\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training this agent for 5000 steps gives a noticeable improvement over the untrained model (assuming you get lucky with randomization).\n",
    "\n",
    "You can visualize the results of training by setting `render = True` for the next section.\n",
    "This is set to `False` by default because there are issues with rendering and jupyter notebooks."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "render = False\n",
    "obs = env.reset()\n",
    "for i in range(1000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "    if render:\n",
    "      env.render()\n",
    "    if done:\n",
    "      obs = env.reset()\n",
    "\n",
    "env.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training using a custom environment\n",
    "\n",
    "A custom environment can be found in [stateless_cartpole](custom_env/stateless_cartpole.py).\n",
    "This environment is heavily patterned from `CartPole-v1` with one key difference: the state observations are now limited to the positions,\n",
    "$$\\mathrm{state} = \\left[x, \\theta \\right].$$\n",
    "This configuration was designed as an example of the `rllib` [project](https://github.com/ray-project/ray/blob/master/rllib/examples/env/stateless_cartpole.py) to demonstrate an example where a fully connected neural network policy is insufficient to learn the cartpole problem (this is an example of a partially-observable markov process).\n",
    "The primary changes in this custom environment can be found in the observation space.\n",
    "\n",
    "The next section of code demonstrates how to load your custom environment, as well as tweaking your `stable_baselines` experiment to use the appropriate models."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from custom_env.stateless_cartpole import StatelessCartPole\n",
    "env = StatelessCartPole()\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "policy_kwargs = dict(layers=[16, 16, 16])\n",
    "model = PPO2(MlpLstmPolicy, env, nminibatches=1, verbose=1)\n",
    "# model = PPO2(MlpPolicy, env, verbose=1)\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=100)\n",
    "\n",
    "model.learn(total_timesteps=5000)\n",
    "\n",
    "print(f\"Untrained mean_reward:\\t{mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=100)\n",
    "print(f\"Trained mean_reward:\\t{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/damian/anaconda3/envs/deeprl/lib/python3.7/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "---------------------------------------\n",
      "| approxkl           | 1.8278017e-08  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.000102      |\n",
      "| fps                | 26             |\n",
      "| n_updates          | 1              |\n",
      "| policy_entropy     | 0.69314694     |\n",
      "| policy_loss        | -6.5215863e-06 |\n",
      "| serial_timesteps   | 128            |\n",
      "| time_elapsed       | 1e-05          |\n",
      "| total_timesteps    | 128            |\n",
      "| value_loss         | 48.960938      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.088178e-08  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.00057      |\n",
      "| fps                | 139           |\n",
      "| n_updates          | 2             |\n",
      "| policy_entropy     | 0.69314694    |\n",
      "| policy_loss        | -2.626516e-05 |\n",
      "| serial_timesteps   | 256           |\n",
      "| time_elapsed       | 4.85          |\n",
      "| total_timesteps    | 256           |\n",
      "| value_loss         | 39.527786     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.3555226e-07 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 0.000714      |\n",
      "| fps                | 194           |\n",
      "| n_updates          | 3             |\n",
      "| policy_entropy     | 0.6931428     |\n",
      "| policy_loss        | -8.112006e-05 |\n",
      "| serial_timesteps   | 384           |\n",
      "| time_elapsed       | 5.76          |\n",
      "| total_timesteps    | 384           |\n",
      "| value_loss         | 64.95592      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| approxkl           | 1.8787054e-08   |\n",
      "| clipfrac           | 0.0             |\n",
      "| explained_variance | 0.0014          |\n",
      "| fps                | 208             |\n",
      "| n_updates          | 4               |\n",
      "| policy_entropy     | 0.6931448       |\n",
      "| policy_loss        | -1.00862235e-05 |\n",
      "| serial_timesteps   | 512             |\n",
      "| time_elapsed       | 6.42            |\n",
      "| total_timesteps    | 512             |\n",
      "| value_loss         | 39.94852        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 3.6185888e-08  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.00163        |\n",
      "| fps                | 156            |\n",
      "| n_updates          | 5              |\n",
      "| policy_entropy     | 0.6931449      |\n",
      "| policy_loss        | -2.0601787e-05 |\n",
      "| serial_timesteps   | 640            |\n",
      "| time_elapsed       | 7.04           |\n",
      "| total_timesteps    | 640            |\n",
      "| value_loss         | 42.89695       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 3.0525488e-08  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.00174       |\n",
      "| fps                | 140            |\n",
      "| n_updates          | 6              |\n",
      "| policy_entropy     | 0.69314444     |\n",
      "| policy_loss        | -1.0688789e-05 |\n",
      "| serial_timesteps   | 768            |\n",
      "| time_elapsed       | 7.86           |\n",
      "| total_timesteps    | 768            |\n",
      "| value_loss         | 30.094         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.7466633e-08 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.00303      |\n",
      "| fps                | 179           |\n",
      "| n_updates          | 7             |\n",
      "| policy_entropy     | 0.6931443     |\n",
      "| policy_loss        | -8.427072e-06 |\n",
      "| serial_timesteps   | 896           |\n",
      "| time_elapsed       | 8.77          |\n",
      "| total_timesteps    | 896           |\n",
      "| value_loss         | 31.137547     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.6345629e-09 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.00407      |\n",
      "| fps                | 271           |\n",
      "| n_updates          | 8             |\n",
      "| policy_entropy     | 0.693143      |\n",
      "| policy_loss        | 1.1292286e-07 |\n",
      "| serial_timesteps   | 1024          |\n",
      "| time_elapsed       | 9.48          |\n",
      "| total_timesteps    | 1024          |\n",
      "| value_loss         | 33.568954     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.6380143e-08  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | 0.00114        |\n",
      "| fps                | 201            |\n",
      "| n_updates          | 9              |\n",
      "| policy_entropy     | 0.6931447      |\n",
      "| policy_loss        | -2.7966686e-05 |\n",
      "| serial_timesteps   | 1152           |\n",
      "| time_elapsed       | 9.95           |\n",
      "| total_timesteps    | 1152           |\n",
      "| value_loss         | 41.38823       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.1302828e-08 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.00454      |\n",
      "| fps                | 180           |\n",
      "| n_updates          | 10            |\n",
      "| policy_entropy     | 0.69314265    |\n",
      "| policy_loss        | -2.662721e-05 |\n",
      "| serial_timesteps   | 1280          |\n",
      "| time_elapsed       | 10.6          |\n",
      "| total_timesteps    | 1280          |\n",
      "| value_loss         | 52.708817     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.1855944e-07 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | 7.24e-05      |\n",
      "| fps                | 230           |\n",
      "| n_updates          | 11            |\n",
      "| policy_entropy     | 0.69314486    |\n",
      "| policy_loss        | -2.122391e-05 |\n",
      "| serial_timesteps   | 1408          |\n",
      "| time_elapsed       | 11.3          |\n",
      "| total_timesteps    | 1408          |\n",
      "| value_loss         | 41.106308     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.1913626e-07 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0274       |\n",
      "| fps                | 220           |\n",
      "| n_updates          | 12            |\n",
      "| policy_entropy     | 0.69314235    |\n",
      "| policy_loss        | 1.608557e-05  |\n",
      "| serial_timesteps   | 1536          |\n",
      "| time_elapsed       | 11.9          |\n",
      "| total_timesteps    | 1536          |\n",
      "| value_loss         | 26.20343      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.8905583e-07  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.0327        |\n",
      "| fps                | 198            |\n",
      "| n_updates          | 13             |\n",
      "| policy_entropy     | 0.69314057     |\n",
      "| policy_loss        | -5.5545825e-05 |\n",
      "| serial_timesteps   | 1664           |\n",
      "| time_elapsed       | 12.4           |\n",
      "| total_timesteps    | 1664           |\n",
      "| value_loss         | 39.592266      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.7802344e-07 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0437       |\n",
      "| fps                | 227           |\n",
      "| n_updates          | 14            |\n",
      "| policy_entropy     | 0.693139      |\n",
      "| policy_loss        | 5.830312e-05  |\n",
      "| serial_timesteps   | 1792          |\n",
      "| time_elapsed       | 13.1          |\n",
      "| total_timesteps    | 1792          |\n",
      "| value_loss         | 47.02358      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.6463516e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.0775       |\n",
      "| fps                | 183           |\n",
      "| n_updates          | 15            |\n",
      "| policy_entropy     | 0.69307804    |\n",
      "| policy_loss        | -9.347964e-05 |\n",
      "| serial_timesteps   | 1920          |\n",
      "| time_elapsed       | 13.7          |\n",
      "| total_timesteps    | 1920          |\n",
      "| value_loss         | 44.70082      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.3423483e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.158        |\n",
      "| fps                | 234           |\n",
      "| n_updates          | 16            |\n",
      "| policy_entropy     | 0.69267774    |\n",
      "| policy_loss        | 0.0007008987  |\n",
      "| serial_timesteps   | 2048          |\n",
      "| time_elapsed       | 14.3          |\n",
      "| total_timesteps    | 2048          |\n",
      "| value_loss         | 42.33001      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00034462308 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.475        |\n",
      "| fps                | 235           |\n",
      "| n_updates          | 17            |\n",
      "| policy_entropy     | 0.6930011     |\n",
      "| policy_loss        | 0.0016349917  |\n",
      "| serial_timesteps   | 2176          |\n",
      "| time_elapsed       | 14.9          |\n",
      "| total_timesteps    | 2176          |\n",
      "| value_loss         | 38.57298      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.0874303e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.194        |\n",
      "| fps                | 190           |\n",
      "| n_updates          | 18            |\n",
      "| policy_entropy     | 0.6927931     |\n",
      "| policy_loss        | -0.001229845  |\n",
      "| serial_timesteps   | 2304          |\n",
      "| time_elapsed       | 15.4          |\n",
      "| total_timesteps    | 2304          |\n",
      "| value_loss         | 49.738926     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0014674556  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.458        |\n",
      "| fps                | 207           |\n",
      "| n_updates          | 19            |\n",
      "| policy_entropy     | 0.68674344    |\n",
      "| policy_loss        | -0.0021009988 |\n",
      "| serial_timesteps   | 2432          |\n",
      "| time_elapsed       | 16.1          |\n",
      "| total_timesteps    | 2432          |\n",
      "| value_loss         | 31.893127     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0006343905 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -0.978       |\n",
      "| fps                | 193          |\n",
      "| n_updates          | 20           |\n",
      "| policy_entropy     | 0.67502886   |\n",
      "| policy_loss        | 0.00319483   |\n",
      "| serial_timesteps   | 2560         |\n",
      "| time_elapsed       | 16.7         |\n",
      "| total_timesteps    | 2560         |\n",
      "| value_loss         | 23.597694    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.1715528e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.708        |\n",
      "| fps                | 188           |\n",
      "| n_updates          | 21            |\n",
      "| policy_entropy     | 0.66170865    |\n",
      "| policy_loss        | 0.0014751947  |\n",
      "| serial_timesteps   | 2688          |\n",
      "| time_elapsed       | 17.4          |\n",
      "| total_timesteps    | 2688          |\n",
      "| value_loss         | 28.54903      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 8.520048e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.387         |\n",
      "| fps                | 227            |\n",
      "| n_updates          | 22             |\n",
      "| policy_entropy     | 0.65613174     |\n",
      "| policy_loss        | -0.00013898755 |\n",
      "| serial_timesteps   | 2816           |\n",
      "| time_elapsed       | 18.1           |\n",
      "| total_timesteps    | 2816           |\n",
      "| value_loss         | 40.012714      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00023186154 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.602        |\n",
      "| fps                | 160           |\n",
      "| n_updates          | 23            |\n",
      "| policy_entropy     | 0.6698604     |\n",
      "| policy_loss        | -0.0008393773 |\n",
      "| serial_timesteps   | 2944          |\n",
      "| time_elapsed       | 18.6          |\n",
      "| total_timesteps    | 2944          |\n",
      "| value_loss         | 26.242863     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00041284948 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.769        |\n",
      "| fps                | 290           |\n",
      "| n_updates          | 24            |\n",
      "| policy_entropy     | 0.6792864     |\n",
      "| policy_loss        | -0.0020055708 |\n",
      "| serial_timesteps   | 3072          |\n",
      "| time_elapsed       | 19.4          |\n",
      "| total_timesteps    | 3072          |\n",
      "| value_loss         | 24.770977     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00083733717 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.681        |\n",
      "| fps                | 291           |\n",
      "| n_updates          | 25            |\n",
      "| policy_entropy     | 0.68927944    |\n",
      "| policy_loss        | -0.0035467837 |\n",
      "| serial_timesteps   | 3200          |\n",
      "| time_elapsed       | 19.9          |\n",
      "| total_timesteps    | 3200          |\n",
      "| value_loss         | 20.279325     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0011064635 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -0.306       |\n",
      "| fps                | 291          |\n",
      "| n_updates          | 26           |\n",
      "| policy_entropy     | 0.6926748    |\n",
      "| policy_loss        | 0.0011273623 |\n",
      "| serial_timesteps   | 3328         |\n",
      "| time_elapsed       | 20.3         |\n",
      "| total_timesteps    | 3328         |\n",
      "| value_loss         | 33.13478     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0003858407  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.348        |\n",
      "| fps                | 297           |\n",
      "| n_updates          | 27            |\n",
      "| policy_entropy     | 0.68910074    |\n",
      "| policy_loss        | -0.0012368886 |\n",
      "| serial_timesteps   | 3456          |\n",
      "| time_elapsed       | 20.8          |\n",
      "| total_timesteps    | 3456          |\n",
      "| value_loss         | 33.787025     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00038611377 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.404        |\n",
      "| fps                | 274           |\n",
      "| n_updates          | 28            |\n",
      "| policy_entropy     | 0.6822831     |\n",
      "| policy_loss        | 0.000608078   |\n",
      "| serial_timesteps   | 3584          |\n",
      "| time_elapsed       | 21.2          |\n",
      "| total_timesteps    | 3584          |\n",
      "| value_loss         | 27.099995     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.070728e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.191        |\n",
      "| fps                | 303           |\n",
      "| n_updates          | 29            |\n",
      "| policy_entropy     | 0.6753535     |\n",
      "| policy_loss        | 0.00036375457 |\n",
      "| serial_timesteps   | 3712          |\n",
      "| time_elapsed       | 21.7          |\n",
      "| total_timesteps    | 3712          |\n",
      "| value_loss         | 36.504242     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.5456011e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.556        |\n",
      "| fps                | 303           |\n",
      "| n_updates          | 30            |\n",
      "| policy_entropy     | 0.6737614     |\n",
      "| policy_loss        | -7.882388e-05 |\n",
      "| serial_timesteps   | 3840          |\n",
      "| time_elapsed       | 22.1          |\n",
      "| total_timesteps    | 3840          |\n",
      "| value_loss         | 25.076866     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.8799324e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| explained_variance | -0.679         |\n",
      "| fps                | 213            |\n",
      "| n_updates          | 31             |\n",
      "| policy_entropy     | 0.6729968      |\n",
      "| policy_loss        | 0.000106375664 |\n",
      "| serial_timesteps   | 3968           |\n",
      "| time_elapsed       | 22.5           |\n",
      "| total_timesteps    | 3968           |\n",
      "| value_loss         | 21.155445      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.76011e-05   |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.335        |\n",
      "| fps                | 201           |\n",
      "| n_updates          | 32            |\n",
      "| policy_entropy     | 0.6741588     |\n",
      "| policy_loss        | -3.966177e-05 |\n",
      "| serial_timesteps   | 4096          |\n",
      "| time_elapsed       | 23.1          |\n",
      "| total_timesteps    | 4096          |\n",
      "| value_loss         | 26.812855     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.000102908   |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.223        |\n",
      "| fps                | 246           |\n",
      "| n_updates          | 33            |\n",
      "| policy_entropy     | 0.6788198     |\n",
      "| policy_loss        | -0.0011255853 |\n",
      "| serial_timesteps   | 4224          |\n",
      "| time_elapsed       | 23.7          |\n",
      "| total_timesteps    | 4224          |\n",
      "| value_loss         | 29.53852      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00072768284 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.291        |\n",
      "| fps                | 296           |\n",
      "| n_updates          | 34            |\n",
      "| policy_entropy     | 0.6877026     |\n",
      "| policy_loss        | -0.0030164036 |\n",
      "| serial_timesteps   | 4352          |\n",
      "| time_elapsed       | 24.3          |\n",
      "| total_timesteps    | 4352          |\n",
      "| value_loss         | 30.316463     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0005079175 |\n",
      "| clipfrac           | 0.0          |\n",
      "| explained_variance | -0.395       |\n",
      "| fps                | 287          |\n",
      "| n_updates          | 35           |\n",
      "| policy_entropy     | 0.6927953    |\n",
      "| policy_loss        | 0.0018374198 |\n",
      "| serial_timesteps   | 4480         |\n",
      "| time_elapsed       | 24.7         |\n",
      "| total_timesteps    | 4480         |\n",
      "| value_loss         | 22.85785     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00029745037 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.135        |\n",
      "| fps                | 125           |\n",
      "| n_updates          | 36            |\n",
      "| policy_entropy     | 0.69254124    |\n",
      "| policy_loss        | -0.0029755947 |\n",
      "| serial_timesteps   | 4608          |\n",
      "| time_elapsed       | 25.1          |\n",
      "| total_timesteps    | 4608          |\n",
      "| value_loss         | 30.240509     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00067453424 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.423        |\n",
      "| fps                | 278           |\n",
      "| n_updates          | 37            |\n",
      "| policy_entropy     | 0.6876389     |\n",
      "| policy_loss        | 7.6582655e-06 |\n",
      "| serial_timesteps   | 4736          |\n",
      "| time_elapsed       | 26.2          |\n",
      "| total_timesteps    | 4736          |\n",
      "| value_loss         | 22.66716      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00010958715 |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.503        |\n",
      "| fps                | 165           |\n",
      "| n_updates          | 38            |\n",
      "| policy_entropy     | 0.681015      |\n",
      "| policy_loss        | 0.0004841946  |\n",
      "| serial_timesteps   | 4864          |\n",
      "| time_elapsed       | 26.6          |\n",
      "| total_timesteps    | 4864          |\n",
      "| value_loss         | 20.652311     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.308404e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| explained_variance | -0.262        |\n",
      "| fps                | 239           |\n",
      "| n_updates          | 39            |\n",
      "| policy_entropy     | 0.6797873     |\n",
      "| policy_loss        | -0.0012045414 |\n",
      "| serial_timesteps   | 4992          |\n",
      "| time_elapsed       | 27.4          |\n",
      "| total_timesteps    | 4992          |\n",
      "| value_loss         | 31.668259     |\n",
      "--------------------------------------\n",
      "Untrained mean_reward:\t9.18 +/- 1.23\n",
      "Trained mean_reward:\t9.37 +/- 0.76\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Apparently, there are also some changes to the replay loop when using an LSTM policy."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# obs = env.reset()\n",
    "# for i in range(1000):\n",
    "#     action, _states = model.predict(obs)\n",
    "#     obs, rewards, done, info = env.step(action)\n",
    "#     env.render() # uncomment to render\n",
    "#     if done:\n",
    "#       obs = env.reset()\n",
    "\n",
    "# env.close()\n",
    "\n",
    "obs = env.reset()\n",
    "# Passing state=None to the predict function means\n",
    "# it is the initial state\n",
    "state = None\n",
    "# When using VecEnv, done is a vector\n",
    "done = [False for _ in range(env.num_envs)]\n",
    "for _ in range(1000):\n",
    "    # We need to pass the previous state and a mask for recurrent policies\n",
    "    # to reset lstm state when a new episode begin\n",
    "    action, state = model.predict(obs, state=state, mask=done)\n",
    "    obs, reward , done, _ = env.step(action)\n",
    "    # Note: with VecEnv, env.reset() is automatically called\n",
    "\n",
    "    # Show the env\n",
    "    # env.render()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "And that's it!\n",
    "We have loaded and trained a custom environment!\n",
    "\n",
    "## Other Examples\n",
    "* [Stock Market](https://towardsdatascience.com/creating-a-custom-openai-gym-environment-for-stock-trading-be532be3910e)\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('deeprl': conda)"
  },
  "interpreter": {
   "hash": "076769b36631b251377a41d0217de183765446cbd030cd0c48c38a7a0d762485"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}